{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Conv1D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "\n",
    "import neuralNets\n",
    "\n",
    "def oneHotEncodeData3Classes(targets):\n",
    "    j=0\n",
    "    Y_val = np.zeros((targets.shape[0], 3))\n",
    "    for j in range(targets.shape[0]):\n",
    "        if targets[j] == 0:\n",
    "            Y_val[j, 0] = 1\n",
    "        elif targets[j] == 1:\n",
    "            Y_val[j, 1] = 1\n",
    "        elif targets[j] == 2:\n",
    "            Y_val[j, 2] = 1\n",
    "        else:\n",
    "            print(\"something went wrong, new class\", targets[j])\n",
    "    return Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeTrainingData(X_train_2D):\n",
    "    j = 0\n",
    "    n_trainingSamples, n_features = X_train_2D.shape\n",
    "    n_classes = 5\n",
    "    X_train_3D = np.zeros((n_trainingSamples, n_features, n_classes))\n",
    "    for j in range(n_trainingSamples):\n",
    "        for i in range(n_features):\n",
    "            curValue = X_train[j, i]\n",
    "            if curValue == 0:\n",
    "                X_train_3D[j, i, 0] = 1\n",
    "            elif curValue == 0.25:\n",
    "                X_train_3D[j, i, 1] = 1\n",
    "            elif curValue == 0.5:\n",
    "                X_train_3D[j, i, 2] = 1\n",
    "            elif curValue == 0.75:\n",
    "                X_train_3D[j, i, 3] = 1\n",
    "            elif curValue == 1:\n",
    "                X_train_3D[j, i, 4] = 1\n",
    "            else:\n",
    "                print(\"something went wrong, new class\", curValue)\n",
    "                \n",
    "    return X_train_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"data/numerai_datasets_25.04.21/numerai_training_data.csv\")\n",
    "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n",
    "\n",
    "training_data[feature_cols] = training_data[feature_cols].astype(np.float16)\n",
    "training_data.target        = training_data.target.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv(\"data/numerai_datasets_25.04.21/numerai_validation_data.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[feature_cols].to_numpy()\n",
    "\n",
    "X_train_3D = encodeTrainingData(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation_data[feature_cols].to_numpy()\n",
    "X_val_3D = encodeTrainingData(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = training_data.target\n",
    "\n",
    "Y_train_3class = Y_train.replace(1, 0)\n",
    "Y_train_3class = Y_train_3class.replace([0.25, 0.75], 1)\n",
    "Y_train_3class = Y_train_3class.replace(0.5, 2)\n",
    "\n",
    "X_train_3class = X_train_3D\n",
    "Y_train_3class = Y_train_3class.to_numpy()\n",
    "\n",
    "X_train_3class, Y_train_3class = shuffle(X_train_3class, Y_train_3class)\n",
    "\n",
    "X_train_3class, X_test_3class, Y_train_3class, Y_test_3class = train_test_split(X_train_3class, Y_train_3class, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_3class = validation_data.target\n",
    "\n",
    "Y_val_3class = Y_val_3class.replace(1, 0)\n",
    "Y_val_3class = Y_val_3class.replace([0.25, 0.75], 1)\n",
    "Y_val_3class = Y_val_3class.replace(0.5, 2).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineNN_3classes_3D(n_inputFeatures, n_classes):\n",
    "    activation = \"relu\"\n",
    "    regularizationConst_l1 = 0.00000#3\n",
    "    regularizationConst_l2 = 0.00000#3\n",
    "    #size = 512\n",
    "    X_input = Input(shape=(n_inputFeatures, n_classes,1, ))\n",
    "    X = Conv2D(32, (2,2), activation = activation, input_shape = (n_inputFeatures, n_classes, 1))(X_input)\n",
    "    X = MaxPooling2D((2,2))(X)\n",
    "    X = Conv2D(64, (2,2))(X)\n",
    "    X = Flatten()(X)\n",
    "#    X = Dense(128, activation=activation)(X)\n",
    "#    X = Dense(64, activation=activation)(X)\n",
    "    X = Dense(32, activation=activation)(X)\n",
    "    X = Dense(32, activation=activation)(X)\n",
    "    X = Dense(32, activation=activation)(X)\n",
    "    \n",
    "    X = Dense(3, activation=\"softmax\")(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='deepNN')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNN_3classes = defineNN_3classes_3D(X_val_3D.shape[1], X_val_3D.shape[2])\n",
    "optAdam    = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.99)\n",
    "\n",
    "modelNN_3classes.compile(optimizer=optAdam, loss='categorical_crossentropy', metrics='categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_3class_oneHot = oneHotEncodeData3Classes(Y_train_3class)\n",
    "Y_test_3class_oneHot  = oneHotEncodeData3Classes(Y_test_3class)\n",
    "Y_val_3class_oneHot   = oneHotEncodeData3Classes(Y_val_3class)\n",
    "\n",
    "class MyCustomCallback_3class(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        res_eval_1 = self.model.evaluate(X_test_3class, Y_test_3class_oneHot, verbose = 0)\n",
    "        res_eval_2 = self.model.evaluate(X_val_3D, Y_val_3class_oneHot, verbose = 0)\n",
    "        print(\"test \",res_eval_1)\n",
    "        print(\"val\", res_eval_2)\n",
    "my_val_callback_3class = MyCustomCallback_3class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.array([0, 1, 2]), Y_train_3class)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = modelNN_3classes.fit(X_train_3class, Y_train_3class_oneHot, epochs = 10, class_weight=class_weights, batch_size = 128, callbacks = [my_val_callback_3class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
