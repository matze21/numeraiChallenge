{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numerapi\n",
    "import sklearn.linear_model\n",
    "\n",
    "import keras_deepCNN\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow.keras as k\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "def oneHotEncodeData(targets):\n",
    "    j=0\n",
    "    Y_val = np.zeros((targets.shape[0], 5))\n",
    "    for j in range(targets.shape[0]):\n",
    "        if targets[j] == 0:\n",
    "            Y_val[j, 0] = 1\n",
    "        elif targets[j] == 0.25:\n",
    "            Y_val[j, 1] = 1\n",
    "        elif targets[j] == 0.5:\n",
    "            Y_val[j, 2] = 1\n",
    "        elif targets[j] == 0.75:\n",
    "            Y_val[j, 3] = 1\n",
    "        elif targets[j] == 1.0:\n",
    "            Y_val[j, 4] = 1\n",
    "        else:\n",
    "            print(\"something went wrong, new class\", targets[j])\n",
    "    return Y_val\n",
    "\n",
    "useValidationData=True\n",
    "\n",
    "tic = time.time()\n",
    "#training_data = pd.read_csv(\"appendedTrainingData_test12021-01-31_2021-03-21.csv\")\n",
    "training_data = pd.read_csv(\"data/numerai_datasets_04.04.21/numerai_training_data.csv\")\n",
    "\n",
    "training_data = training_data.drop_duplicates()\n",
    "\n",
    "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n",
    "X_train = training_data[feature_cols].to_numpy()\n",
    "#Y_train = training_data.loc[:,['label_0', 'label_025', 'label_05', 'label_075', 'label_1']].to_numpy()\n",
    "Y_train = training_data.target.to_numpy()\n",
    "\n",
    "if useValidationData:\n",
    "    tournament_data = pd.read_csv(\"data/numerai_datasets_04.04.21/numerai_tournament_data.csv\")\n",
    "    validation_data = tournament_data.loc[tournament_data.data_type == 'validation']\n",
    "    X_val = validation_data[feature_cols].reset_index().drop(['index'], axis = 1).to_numpy()\n",
    "    #X_pred = tournamend_data.loc[tournament_data.data_type == \"\"]\n",
    "    Y_val = validation_data.target.to_numpy()\n",
    "\n",
    "\n",
    "toc = time.time()\n",
    "print(\"processed the data took \", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "toc = time.time()\n",
    "print(\"shuffle the data took \", toc - tic)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.array([0, 0.25, 0.5, 0.75, 1]), Y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "tic = time.time()\n",
    "Y_train = oneHotEncodeData(Y_train)\n",
    "Y_val = oneHotEncodeData(Y_val)\n",
    "toc = time.time()\n",
    "print(\"encode the data took \", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @keras_export('keras.metrics.categorical_accuracy')\n",
    "# @dispatch.add_dispatch_support\n",
    "import tensorflow as tf\n",
    "def max_accuracy(y_true, y_pred):\n",
    "  \"\"\"Calculates how often the max prediction matches one-hot labels.\"\"\"\n",
    "  retVal = 0\n",
    "  \n",
    "  if y_true.shape[0] != None:  \n",
    "    num_correct_classified = tf.math.argmax(y_true,axis = 1) == tf.math.argmax(y_pred, axis = 1)\n",
    "    num = tf.reduce_sum(tf.dtypes.cast(num_correct_classified, tf.int32), axis = -1)\n",
    "    retVal = num / y_true.shape[0]\n",
    "  else:\n",
    "    retVal = tf.dtypes.cast(tf.math.argmax(y_true,axis = 1) == tf.math.argmax(y_pred, axis = 1), tf.int32)\n",
    "  return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputFeatures = X_train.shape[1]\n",
    "activation = \"relu\"\n",
    "regularizationConst_l1 = 0.0002\n",
    "regularizationConst_l2 = 0.0001\n",
    "size = 512\n",
    "X_input = Input(shape=(n_inputFeatures,))\n",
    "X = Dropout(0.5, input_shape = (n_inputFeatures,))(X_input)\n",
    " \n",
    "X = Dense(size, activation=activation, kernel_regularizer=regularizers.l1_l2(l1=regularizationConst_l1, l2=regularizationConst_l2), bias_regularizer=regularizers.l2(regularizationConst_l2), activity_regularizer=regularizers.l2(regularizationConst_l2))(X)\n",
    "    #X = Dropout(dropoutRate, input_shape = (size,))(X)\n",
    "X = BatchNormalization(axis = -1)(X)\n",
    "X = Dense(size, activation=activation, kernel_regularizer=regularizers.l1_l2(l1=regularizationConst_l1, l2=regularizationConst_l2), bias_regularizer=regularizers.l2(regularizationConst_l2), activity_regularizer=regularizers.l2(regularizationConst_l2))(X)\n",
    "    #X = Dropout(dropoutRate, input_shape = (size,))(X)\n",
    "X = BatchNormalization(axis = -1)(X)\n",
    "X = Dense(size, activation=activation, kernel_regularizer=regularizers.l1_l2(l1=regularizationConst_l1, l2=regularizationConst_l2), bias_regularizer=regularizers.l2(regularizationConst_l2), activity_regularizer=regularizers.l2(regularizationConst_l2))(X)\n",
    "    #X = Dropout(dropoutRate, input_shape = (size,))(X)\n",
    "X = BatchNormalization(axis = -1)(X)\n",
    "X = Dense(5, activation=\"softmax\")(X)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs = X_input, outputs = X, name='deepNN')\n",
    "\n",
    "METRICS = [\n",
    "    #   k.metrics.TruePositives(name='tp'),\n",
    "    #   k.metrics.FalsePositives(name='fp'),\n",
    "    #   k.metrics.TrueNegatives(name='tn'),\n",
    "    #   k.metrics.FalseNegatives(name='fn'), \n",
    "#       k.metrics.CategoricalAccuracy(name='cat_accuracy'),\n",
    "#       k.metrics.Precision(name='precision'),\n",
    "#       k.metrics.Recall(name='recall'),\n",
    "      max_accuracy,\n",
    "    #   k.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics=METRICS)\n",
    "#model.load_weights(\"model.h5\")\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs = 50, batch_size = 256*256, class_weight=class_weights, validation_data=(X_val, Y_val))\n",
    "#import pdb; pdb.set_trace()\n",
    "#model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "#print(history.history)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights(\"model.h5\")\n",
    "y_pred_oneHot = model.predict(X_val)\n",
    "\n",
    "pred = np.argmax(y_pred_oneHot, axis = 1) / 4\n",
    "print(y_pred_oneHot, pred)\n",
    "    \n",
    "\n",
    "predictions_df = validation_data[\"id\"].to_frame()\n",
    "predictions_df[\"pred\"] = pred\n",
    "predictions_df.pred.hist(bins = 10)\n",
    "print(len(predictions_df.loc[predictions_df.pred != 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_oneHot = model.predict(X_train)\n",
    "\n",
    "pred = np.argmax(y_pred_oneHot, axis = 1) / 4\n",
    "print(y_pred_oneHot, pred)\n",
    "    \n",
    "\n",
    "predictions_df = training_data[\"id\"].to_frame()\n",
    "predictions_df[\"pred\"] = pred\n",
    "predictions_df.pred.hist(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tour = tournament_data[feature_cols].reset_index().drop(['index'], axis = 1).to_numpy()\n",
    "predictions = model.predict(X_tour)\n",
    "\n",
    "i=0\n",
    "predictionVektor = np.zeros((predictions.shape[0]))\n",
    "for i in range(predictions.shape[0]):\n",
    "    maxPos = np.argmax(predictions[i,:])\n",
    "    if maxPos == 0:\n",
    "        predictionVektor[i] = 0\n",
    "    elif maxPos == 1:\n",
    "        predictionVektor[i] = 0.25\n",
    "    elif maxPos == 2:\n",
    "        predictionVektor[i] = 0.5\n",
    "    elif maxPos == 3:\n",
    "        predictionVektor[i] = 0.75\n",
    "    elif maxPos == 4:\n",
    "        predictionVektor[i] = 1.0\n",
    "    else:\n",
    "        print(\"something went wrong, new class\", Y_train_npArray[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = tournament_data[\"id\"].to_frame()\n",
    "predictions_df[\"prediction_kazutsugi\"] = predictionVektor\n",
    "predictions_df.head()\n",
    "\n",
    "predictions_df.to_csv(\"predictions_040421.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numerapi\n",
    "public_id  = \"5PKOLW4ZJQDSMTC2QWPPG2QEHB427MFJ\"\n",
    "secret_key = \"I26YRNIBRQF47E6SO6VMLTLGN4O2MHL6ADUB4JNNQAYW3DPCH6JKY4HS5R2PYKLB\"\n",
    "model_id   = \"e994d440-764d-495d-8d60-7dbac3ac615b\"\n",
    "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n",
    "submission_id = napi.upload_predictions(\"predictions_040421.csv\", model_id=model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
