{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "TRAINING_DATAPATH = 'data/numerai_datasets_04.04.21/numerai_training_data.csv'\n",
    "df = pd.read_csv(TRAINING_DATAPATH)\n",
    "features = [c for c in df if c.startswith(\"feature\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_data = pd.read_csv(\"data/numerai_datasets_04.04.21/numerai_tournament_data.csv\")  \n",
    "    \n",
    "\n",
    "validation_data = tournament_data.loc[tournament_data.data_type == 'validation']\n",
    "X_val = validation_data[features].reset_index().drop(['index'], axis = 1)\n",
    "Y_val = validation_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ar1(x):\n",
    "    return np.corrcoef(x[:-1], x[1:])[0,1]\n",
    "\n",
    "def autocorr_penalty(x):\n",
    "    n = len(x)\n",
    "    p = ar1(x)\n",
    "    return np.sqrt(1 + 2*np.sum([((n - i)/n)*p**i for i in range(1,n)]))\n",
    "\n",
    "def smart_sharpe(x):\n",
    "    return np.mean(x)/(np.std(x, ddof=1)*autocorr_penalty(x))\n",
    "\n",
    "def spearmanr(target, pred):\n",
    "    predictionArray = np.zeros((target.shape[0], 2))\n",
    "    predictionArray[:,0] = target.to_numpy()\n",
    "    predictionArray[:,1] = pred.to_numpy()\n",
    "    score = np.corrcoef(predictionArray\n",
    "#         target,\n",
    "#         pred.rank(pct=True, method=\"first\")\n",
    "    )[0, 1]\n",
    "    if score == -1:\n",
    "        print(predictionArray)\n",
    "    if math.isnan(score):\n",
    "        score = 0\n",
    "    #print(score)\n",
    "    return score\n",
    "\n",
    "def calcMaxAccuracy2(Y_true, Y_pred):\n",
    "    corVal = 0\n",
    "    allTrainSamples = len(Y_pred)\n",
    "    for i in range(allTrainSamples):\n",
    "        if Y_pred[i] == Y_true[i]:\n",
    "            corVal +=1\n",
    "    accuracy = corVal / allTrainSamples\n",
    "    return accuracy\n",
    "\n",
    "def era_boost_train(df, features, proportion=0.5, trees_per_step=10, num_iters=200):\n",
    "    classes = np.array([0, 0.25, 0.5, 0.75, 1])\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.array([0, 0.25, 0.5, 0.75, 1]), df[\"target\"])\n",
    "    w_array = np.ones(df[\"target\"].shape[0], dtype = 'float')\n",
    "    for i, val in enumerate(df[\"target\"]):\n",
    "        index = np.where(classes == val)\n",
    "        w_array[i] = class_weights[index]\n",
    "    \n",
    "    #evalset = [(df[features], df[\"target\"]), (X_val,Y_val)]\n",
    "    model = XGBClassifier(max_depth=5, objective='multi:softprob', learning_rate=0.01, n_estimators=1000, n_jobs=-1, colsample_bytree=0.1)\n",
    "    \n",
    "    model.fit(df[features], df[\"target\"],  sample_weight=w_array)\n",
    "    \n",
    "    for i in range(num_iters-1):\n",
    "        print(f\"iteration {i}\")\n",
    "        # score each era\n",
    "        print(\"predicting on train\")\n",
    "        preds = model.predict(df[features])\n",
    "        df[\"pred\"] = preds\n",
    "        #print(preds)\n",
    "        era_scores = pd.Series(index=df[\"era\"].unique())\n",
    "        print(\"getting per era scores\")\n",
    "        for era in df[\"era\"].unique():\n",
    "            era_predictions_df = df[df[\"era\"] == era]\n",
    "            era_score = calcMaxAccuracy2(era_predictions_df[\"pred\"].to_numpy(), era_predictions_df[\"target\"].to_numpy())\n",
    "            era_scores[era] = era_score\n",
    "        #print(era_scores)\n",
    "        era_scores.sort_values(inplace=True)\n",
    "        worst_eras = era_scores[era_scores <= era_scores.quantile(proportion)].index\n",
    "        print(list(worst_eras))\n",
    "        worst_df = df[df[\"era\"].isin(worst_eras)]\n",
    "        era_scores.sort_index(inplace=True)\n",
    "        era_scores.plot(kind=\"bar\")\n",
    "        print(\"performance over time\")\n",
    "        plt.show()\n",
    "        if era_scores.sum() > 0:\n",
    "            print(\"autocorrelation\")\n",
    "            print(ar1(era_scores))\n",
    "            print(\"mean correlation\")\n",
    "            print(np.mean(era_scores))\n",
    "            print(\"sharpe\")\n",
    "            print(np.mean(era_scores)/np.std(era_scores))\n",
    "            print(\"smart sharpe\")\n",
    "            print(smart_sharpe(era_scores))\n",
    "        model.n_estimators += trees_per_step\n",
    "        booster = model.get_booster()\n",
    "        print(\"fitting on worst eras\")\n",
    "        \n",
    "        class_weights = class_weight.compute_class_weight('balanced', np.array([0, 0.25, 0.5, 0.75, 1]), worst_df[\"target\"])\n",
    "        w_array = np.ones(worst_df[\"target\"].shape[0], dtype = 'float')\n",
    "        for i, val in enumerate(worst_df[\"target\"]):\n",
    "            index = np.where(classes == val)\n",
    "            w_array[i] = class_weights[index]\n",
    "        \n",
    "        model.fit(worst_df[features], worst_df[\"target\"], sample_weight=w_array, xgb_model=booster)\n",
    "    return model\n",
    "\n",
    "boost_model = era_boost_train(df, features, proportion=0.5, trees_per_step=10, num_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[features]\n",
    "Y_train = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = boost_model.predict(X_train)\n",
    "corVal = 0\n",
    "allTrainSamples = len(Y_train_pred)\n",
    "for i in range(allTrainSamples):\n",
    "    if int(Y_train_pred[i]*4) == Y_train[i]*4:\n",
    "        corVal +=1\n",
    "accuracy = corVal / allTrainSamples\n",
    "print(\"train accuracy = \", accuracy)\n",
    "\n",
    "\n",
    "y_pred = boost_model.predict(X_val)\n",
    "corVal = 0\n",
    "allTrainSamples = len(y_pred)\n",
    "for i in range(allTrainSamples):\n",
    "    if y_pred[i] == Y_val[i]:\n",
    "        corVal +=1\n",
    "accuracy = corVal / allTrainSamples\n",
    "print(\"validation accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = validation_data[\"id\"].to_frame()\n",
    "predictions_df[\"pred\"] = y_pred\n",
    "predictions_df.pred.hist(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = training_data[\"id\"].to_frame()\n",
    "predictions_df[\"pred\"] = Y_train_pred\n",
    "predictions_df.pred.hist(bins = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
