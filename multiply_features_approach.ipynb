{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "\n",
    "import neuralNets\n",
    "\n",
    "def oneHotEncodeData3Classes(targets):\n",
    "    j=0\n",
    "    Y_val = np.zeros((targets.shape[0], 3))\n",
    "    for j in range(targets.shape[0]):\n",
    "        if targets[j] == 0:\n",
    "            Y_val[j, 0] = 1\n",
    "        elif targets[j] == 1:\n",
    "            Y_val[j, 1] = 1\n",
    "        elif targets[j] == 2:\n",
    "            Y_val[j, 2] = 1\n",
    "        else:\n",
    "            print(\"something went wrong, new class\", targets[j])\n",
    "    return Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"data/numerai_datasets_25.04.21/numerai_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv(\"data/numerai_datasets_25.04.21/numerai_validation_data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3class = training_data[feature_cols]\n",
    "Y_train_3class = training_data.target\n",
    "\n",
    "Y_train_3class = Y_train_3class.replace(1, 0)\n",
    "Y_train_3class = Y_train_3class.replace([0.25, 0.75], 1)\n",
    "Y_train_3class = Y_train_3class.replace(0.5, 2)\n",
    "\n",
    "X_train_3class = X_train_3class.to_numpy()\n",
    "Y_train_3class = Y_train_3class.to_numpy()\n",
    "\n",
    "X_train_3class, Y_train_3class = shuffle(X_train_3class, Y_train_3class)\n",
    "\n",
    "X_train_3class, X_test_3class, Y_train_3class, Y_test_3class = train_test_split(X_train_3class, Y_train_3class, test_size = 0.3)\n",
    "\n",
    "X_val_3class = validation_data[feature_cols]\n",
    "Y_val_3class = validation_data.target\n",
    "\n",
    "Y_val_3class = Y_val_3class.replace(1, 0)\n",
    "Y_val_3class = Y_val_3class.replace([0.25, 0.75], 1)\n",
    "Y_val_3class = Y_val_3class.replace(0.5, 2)\n",
    "\n",
    "X_val_3class = X_val_3class.to_numpy()\n",
    "Y_val_3class = Y_val_3class.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')] \n",
    "features = ['feature_w', 'feature_con','feature_dex','feature_str','feature_cha','feature_int']\n",
    "#print(feature_cols)\n",
    "for feature in features:\n",
    "    sub_features = training_data.columns[training_data.columns.str.startswith(feature)] \n",
    "    print(feature_cols.get_loc(sub_features[0]))\n",
    "    #print(training_data.columns.get_loc(training_data.columns.str.startswith(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3class_int = X_train_3class[:,0:12]\n",
    "X_train_3class_cha = X_train_3class[:,12:98]\n",
    "X_train_3class_str = X_train_3class[:,98:136]\n",
    "X_train_3class_dex = X_train_3class[:,136:150]\n",
    "X_train_3class_con = X_train_3class[:,150:264]\n",
    "X_train_3class_wis = X_train_3class[:,264:310]\n",
    "\n",
    "X_train = [X_train_3class_int, X_train_3class_cha, X_train_3class_str, X_train_3class_dex, X_train_3class_con, X_train_3class_wis]\n",
    "\n",
    "X_test_3class_int = X_test_3class[:,0:12]\n",
    "X_test_3class_cha = X_test_3class[:,12:98]\n",
    "X_test_3class_str = X_test_3class[:,98:136]\n",
    "X_test_3class_dex = X_test_3class[:,136:150]\n",
    "X_test_3class_con = X_test_3class[:,150:264]\n",
    "X_test_3class_wis = X_test_3class[:,264:310]\n",
    "X_test = [X_test_3class_int, X_test_3class_cha, X_test_3class_str, X_test_3class_dex, X_test_3class_con, X_test_3class_wis]\n",
    "\n",
    "X_val_3class_int = X_val_3class[:,0:12]\n",
    "X_val_3class_cha = X_val_3class[:,12:98]\n",
    "X_val_3class_str = X_val_3class[:,98:136]\n",
    "X_val_3class_dex = X_val_3class[:,136:150]\n",
    "X_val_3class_con = X_val_3class[:,150:264]\n",
    "X_val_3class_wis = X_val_3class[:,264:310]\n",
    "X_val = [X_val_3class_int, X_val_3class_cha, X_val_3class_str, X_val_3class_dex, X_val_3class_con, X_val_3class_wis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineNN_3classes(n_wisdom, n_con, n_dex, n_stra, n_cha, n_intel):\n",
    "    activation = \"relu\"\n",
    "    regularizationConst_l1 = 0.00000#3\n",
    "    regularizationConst_l2 = 0.00000#3\n",
    "    #size = 512\n",
    "    W_input  = Input(shape=(n_wisdom,))\n",
    "    W = Dense(32, activation=activation)(W_input)\n",
    "    W = Dense(4, activation=activation)(W)\n",
    "    W = Model(inputs=W_input, outputs=W)\n",
    "    \n",
    "    \n",
    "    CO_input = Input(shape=(n_con,))\n",
    "    CO = Dense(32, activation=activation)(CO_input)\n",
    "    CO = Dense(4, activation=activation)(CO)\n",
    "    CO = Model(inputs=CO_input, outputs=CO)\n",
    "    \n",
    "    D_input  = Input(shape=(n_dex,))\n",
    "    D = Dense(32, activation=activation)(D_input)\n",
    "    D = Dense(4, activation=activation)(D)\n",
    "    D = Model(inputs=D_input, outputs=D)\n",
    "    \n",
    "    S_input  = Input(shape=(n_stra,))\n",
    "    S = Dense(32, activation=activation)(S_input)\n",
    "    S = Dense(4, activation=activation)(S)\n",
    "    S = Model(inputs=S_input, outputs=S)\n",
    "    \n",
    "    CA_input = Input(shape=(n_cha,))\n",
    "    CA = Dense(32, activation=activation)(CA_input)\n",
    "    CA = Dense(4, activation=activation)(CA)\n",
    "    CA = Model(inputs=CA_input, outputs=CA)\n",
    "    \n",
    "    I_input  = Input(shape=(n_intel,))    \n",
    "    I = Dense(32, activation=activation)(I_input)\n",
    "    I = Dense(4, activation=activation)(I)\n",
    "    I = Model(inputs=I_input, outputs=I)\n",
    "    \n",
    "    combined = concatenate([W.output, CO.output])\n",
    "    combined = concatenate([combined, D.output])\n",
    "    combined = concatenate([combined, S.output])\n",
    "    combined = concatenate([combined, CA.output])\n",
    "    combined = concatenate([combined, I.output])\n",
    "    \n",
    "    X = Dense(16, activation=activation)(combined)\n",
    "    X = Dense(8, activation=activation)(X)\n",
    "    \n",
    "    X = Dense(3, activation=\"softmax\")(X)\n",
    "    \n",
    "    model = Model(inputs = combined, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNN_3classes = defineNN_3classes(X_val_3class_int.shape[1], X_val_3class_cha.shape[1], X_val_3class_str.shape[1], X_val_3class_dex.shape[1], X_val_3class_con.shape[1], X_val_3class_wis.shape[1])\n",
    "optAdam    = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.99)\n",
    "\n",
    "modelNN_3classes.compile(optimizer='adam', loss='categorical_crossentropy', metrics='categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_count = 120\n",
    "for i in range(era_count):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n",
    "\n",
    "newFeatures = 0\n",
    "for i in range(len(feature_cols)):\n",
    "    feature1 = feature_cols[i]\n",
    "    for j in range(len(feature_cols)- i - 1):\n",
    "        feature2 = feature_cols[i+j+1]\n",
    "        newFeatures += 1\n",
    "        #data[feature1+feature2] = data[feature1].mul(data[feature2], 1)\n",
    "        \n",
    "        #print(data[feature1], data[feature2], data[feature1+feature2])\n",
    "        #break\n",
    "print(newFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
